{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahaqu\\AppData\\Local\\Temp\\ipykernel_18412\\1360393573.py:15: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "c:\\Users\\ahaqu\\OneDrive\\Desktop\\FYP\\graphRAG\\grag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Step 1: Cleaning existing embeddings...\n",
      "Cleared all existing embeddings\n",
      "\n",
      "Step 2: Recreating vector indexes...\n",
      "Ignoring drop error for node_embeddings_trigger: {code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `db.index.vector.drop` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}\n",
      "Ignoring drop error for node_embeddings_event: {code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `db.index.vector.drop` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}\n",
      "Ignoring drop error for node_embeddings_cause: {code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `db.index.vector.drop` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}\n",
      "Ignoring drop error for node_embeddings_effect: {code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `db.index.vector.drop` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}\n",
      "Created index: node_embeddings_event\n",
      "Created index: node_embeddings_cause\n",
      "Created index: node_embeddings_effect\n",
      "Created index: node_embeddings_trigger\n",
      "\n",
      "Step 3: Regenerating embeddings...\n",
      "Regenerating embeddings for 4388 nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [01:07<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Verification...\n",
      "\n",
      "Embedding Statistics:\n",
      "Event:\n",
      "  Total nodes: 1021\n",
      "  With embeddings: 1021\n",
      "  Coverage: 100.00%\n",
      "Cause:\n",
      "  Total nodes: 1147\n",
      "  With embeddings: 1147\n",
      "  Coverage: 100.00%\n",
      "Effect:\n",
      "  Total nodes: 1118\n",
      "  With embeddings: 1118\n",
      "  Coverage: 100.00%\n",
      "Trigger:\n",
      "  Total nodes: 1102\n",
      "  With embeddings: 1102\n",
      "  Coverage: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class GraphEmbeddingsUpdater:\n",
    "    def __init__(self, graph: Neo4jGraph):\n",
    "        self.graph = graph\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "    def clean_embeddings(self):\n",
    "        \"\"\"Remove all existing embeddings\"\"\"\n",
    "        self.graph.query(\"\"\"\n",
    "        MATCH (n)\n",
    "        WHERE n:Event OR n:Cause OR n:Effect OR n:Trigger\n",
    "        SET n.embedding = null\n",
    "        \"\"\")\n",
    "        print(\"Cleared all existing embeddings\")\n",
    "\n",
    "    def create_vector_index(self):\n",
    "        \"\"\"Create fresh vector indexes with 384 dimensions\"\"\"\n",
    "        # Drop existing indexes first\n",
    "        self._safe_drop_index('node_embeddings_trigger')\n",
    "        self._safe_drop_index('node_embeddings_event')\n",
    "        self._safe_drop_index('node_embeddings_cause')\n",
    "        self._safe_drop_index('node_embeddings_effect')\n",
    "\n",
    "        # Create new indexes\n",
    "        for node_type in ['Event', 'Cause', 'Effect', 'Trigger']:\n",
    "            self._create_single_index(node_type)\n",
    "\n",
    "    def _safe_drop_index(self, index_name: str):\n",
    "        \"\"\"Safely drop index if it exists\"\"\"\n",
    "        try:\n",
    "            self.graph.query(f\"CALL db.index.vector.drop('{index_name}')\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ignoring drop error for {index_name}: {e}\")\n",
    "\n",
    "    def _create_single_index(self, node_type: str):\n",
    "        \"\"\"Create index for a single node type\"\"\"\n",
    "        index_name = f'node_embeddings_{node_type.lower()}'\n",
    "        try:\n",
    "            self.graph.query(f\"\"\"\n",
    "            CALL db.index.vector.createNodeIndex(\n",
    "                '{index_name}',\n",
    "                '{node_type}',\n",
    "                'embedding',\n",
    "                384,\n",
    "                'cosine'\n",
    "            )\n",
    "            \"\"\")\n",
    "            print(f\"Created index: {index_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Index creation warning for {index_name}: {e}\")\n",
    "\n",
    "    def update_node_embeddings(self, batch_size: int = 50):\n",
    "        \"\"\"Regenerate all embeddings from scratch\"\"\"\n",
    "        nodes = self.graph.query(\"\"\"\n",
    "        MATCH (n)\n",
    "        WHERE (n:Event OR n:Cause OR n:Effect OR n:Trigger)\n",
    "        AND n.text IS NOT NULL\n",
    "        RETURN n.id as id, n.text as text\n",
    "        \"\"\")\n",
    "        \n",
    "        print(f\"Regenerating embeddings for {len(nodes)} nodes...\")\n",
    "        \n",
    "        for i in tqdm(range(0, len(nodes), batch_size)):\n",
    "            batch = nodes[i:i + batch_size]\n",
    "            texts = [node['text'] for node in batch]\n",
    "            \n",
    "            embeddings = self.embeddings.embed_documents(texts)\n",
    "            \n",
    "            params = [{\n",
    "                'id': node['id'],\n",
    "                'embedding': emb\n",
    "            } for node, emb in zip(batch, embeddings)]\n",
    "            \n",
    "            self.graph.query(\"\"\"\n",
    "            UNWIND $batch as row\n",
    "            MATCH (n {id: row.id})\n",
    "            SET n.embedding = row.embedding\n",
    "            \"\"\", params={'batch': params})\n",
    "\n",
    "    def verify_embeddings(self):\n",
    "        \"\"\"Verify embedding creation\"\"\"\n",
    "        stats = self.graph.query(\"\"\"\n",
    "        MATCH (n)\n",
    "        WHERE n:Event OR n:Cause OR n:Effect OR n:Trigger\n",
    "        WITH labels(n)[0] as type,\n",
    "             count(n) as total,\n",
    "             count(n.embedding) as with_embedding\n",
    "        RETURN type, total, with_embedding\n",
    "        \"\"\")\n",
    "        \n",
    "        print(\"\\nEmbedding Statistics:\")\n",
    "        for stat in stats:\n",
    "            coverage = (stat['with_embedding'] / stat['total']) * 100\n",
    "            print(f\"{stat['type']}:\")\n",
    "            print(f\"  Total nodes: {stat['total']}\")\n",
    "            print(f\"  With embeddings: {stat['with_embedding']}\")\n",
    "            print(f\"  Coverage: {coverage:.2f}%\")\n",
    "\n",
    "def update_graph_embeddings(graph: Neo4jGraph):\n",
    "    \"\"\"Complete embedding regeneration workflow\"\"\"\n",
    "    updater = GraphEmbeddingsUpdater(graph)\n",
    "    \n",
    "    print(\"Step 1: Cleaning existing embeddings...\")\n",
    "    updater.clean_embeddings()\n",
    "    \n",
    "    print(\"\\nStep 2: Recreating vector indexes...\")\n",
    "    updater.create_vector_index()\n",
    "    \n",
    "    print(\"\\nStep 3: Regenerating embeddings...\")\n",
    "    updater.update_node_embeddings()\n",
    "    \n",
    "    print(\"\\nStep 4: Verification...\")\n",
    "    updater.verify_embeddings()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    graph = Neo4jGraph(\n",
    "        url='bolt://localhost:7687',\n",
    "        username='neo4j',\n",
    "        password=os.getenv('pass')\n",
    "    )\n",
    "    update_graph_embeddings(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
